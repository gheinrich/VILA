cinepile:
  tags:
    - local
  metrics:
    accuracy: overall

egoschema_test:
  tags:
    - submission

egoschema_val:
  tags:
    - core
    - local
  metrics:
    accuracy: accuracy

lmms-ai2d:
  tags:
    - core
    - local
  metrics:
    accuracy: results/ai2d/exact_match,flexible-extract

lmms-chartqa:
  tags:
    - core
    - local
  metrics:
    overall: results/chartqa/relaxed_overall,none
    human: results/chartqa/relaxed_human_split,none
    augmented: results/chartqa/relaxed_augmented_split,none

lmms-docvqa_test:
  tags:
    - submission

lmms-docvqa_val:
  tags:
    - core
    - local
  metrics:
    accuracy: results/docvqa_val/anls,none

lmms-gqa:
  tags:
    - core
    - local
  metrics:
    accuracy: results/gqa/exact_match,none

lmms-infovqa_test:
  tags:
    - submission

lmms-infovqa_val:
  tags:
    - core
    - local
  metrics:
    accuracy: results/infovqa_val/anls,none

lmms-llava-in-the-wild:
  tags:
    - openai

lmms-mmbench:
  tags:
    - submission

lmms-mme:
  tags:
    - core
    - local
  metrics:
    cognition: results/mme/mme_cognition_score,none
    perception: results/mme/mme_percetion_score,none

lmms-mmmu_test:
  tags:
    - submission

lmms-mmmu_val:
  tags:
    - core
    - local
  metrics:
    accuracy: results/mmmu_val/mmmu_acc,none

lmms-mmvet:
  tags:
    - openai

lmms-ocrbench:
  tags:
    - core
    - local
  metrics:
    accuracy: results/ocrbench/ocrbench_accuracy,none

lmms-pope:
  tags:
    - core
    - local
  metrics:
    accuracy: results/pope/pope_accuracy,none
    precision: results/pope/pope_precision,none
    recall: results/pope/pope_recall,none
    f1: results/pope/pope_f1_score,none

lmms-realworldqa:
  tags:
    - core
    - local
  metrics:
    accuracy: results/realworldqa/exact_match,flexible-extract

lmms-seedbench:
  tags:
    - core
    - local
  metrics:
    all: results/seedbench/seed_all,none
    image: results/seedbench/seed_image,none
    video: results/seedbench/seed_video,none

lmms-scienceqa_full:
  tags:
    - core
    - local
  metrics:
    full: results/scienceqa/exact_match,none
    image: results/scienceqa_img/exact_match,none

lmms-textvqa_test:
  tags:
    - submission

lmms-textvqa_val:
  tags:
    - core
    - local
  metrics:
    accuracy: results/textvqa_val/exact_match,none

lmms-videomme:
  tags:
    - video
  metrics:
    accuracy: results/videomme/videomme_percetion_score,none

lmms-vizwiz_vqa_test:
  tags:
    - submission

lmms-vizwiz_vqa_val:
  tags:
    - core
    - local
  metrics:
    accuracy: results/vizwiz_vqa_val/exact_match,none

lmms-vqav2_test:
  tags:
    - submission

lmms-vqav2_val:
  tags:
    - local
  metrics:
    accuracy: results/vqav2_val/exact_match,none

mathvista_test:
  tags:
    - submission

mathvista_testmini:
  tags:
    - core
    - local
  metrics:
    accuracy: average/accuracy

textvqa_val:
  tags:
    - core
    - local
  metrics:
    accuracy: accuracy
