---
ai2d_train_12k:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/workspace/InternVL/internvl_chat/playground/ai2d_train_12k.jsonl
    media_dir: /home/jasonlu/workspace/InternVL/internvl_chat/playground/data/ai2d

captioning_image-paragraph-captioning_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/captioning_image-paragraph-captioning_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/captioning_image-paragraph-captioning_train/images
    no_system_prompt: true

captioning_msrvtt_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/captioning_msrvtt_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/captioning_msrvtt_train/images
    no_system_prompt: true

captioning_textcap_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/captioning_textcap_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/captioning_textcap_train/images
    no_system_prompt: true

chartqa_train_18k:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/workspace/InternVL/internvl_chat/playground/chartqa_train_18k.jsonl
    media_dir: /home/jasonlu/workspace/InternVL/internvl_chat/playground/data/chartqa

docvqa_train_10k:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/workspace/InternVL/internvl_chat/playground/docvqa_train_10k.jsonl
    media_dir: /home/jasonlu/workspace/InternVL/internvl_chat/playground/data/docvqa

dvqa_train_200k:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/workspace/InternVL/internvl_chat/playground/dvqa_train_200k.jsonl
    media_dir: /home/jasonlu/workspace/InternVL/internvl_chat/playground/data/dvqa

generation_visual-dialog_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/generation_visual-dialog_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/generation_visual-dialog_train/images
    no_system_prompt: true

geoqa:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/workspace/InternVL/internvl_chat/playground/geoqa+.jsonl
    media_dir: /home/jasonlu/workspace/InternVL/internvl_chat/playground/data/geoqa+

llava_instruct:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/workspace/InternVL/internvl_chat/playground/llava_instruct_150k_zh.jsonl
    media_dir: /home/jasonlu/workspace/InternVL/internvl_chat/playground/data/coco

m4-instruct-image:
    _target_: llava.data.LLaVANextDataset
    data_path: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/M4-Instruct-Data/m4_instruct_annotations.json
    media_dir: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/M4-Instruct-Data

m4-instruct-image-nuscenes:
    _target_: llava.data.LLaVANextDataset
    data_path: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/M4-Instruct-Data/ligeng_split/nuscenes.json
    media_dir: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/M4-Instruct-Data

m4-instruct-video:
    _target_: llava.data.LLaVANextVideoDataset
    data_path: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/M4-Instruct-Data/m4_instruct_video_filtered.json
    media_dir: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/M4-Instruct-Data/train_video_and_instruction/extracted-jason

math:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/math/data.json

mint-1t-arxiv-captions:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/mint-1t-arxiv/captions-20240904.json
    media_dir: /home/zhijianl/workspace/datasets/mint-1t-arxiv/tiff

reasoning_clevr_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/reasoning_clevr_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/reasoning_clevr_train/images
    no_system_prompt: true

reasoning_nlvr_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/reasoning_nlvr_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/reasoning_nlvr_train/images
    no_system_prompt: true

reasoning_visual-mrc_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/reasoning_visual-mrc_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/reasoning_visual-mrc_train/images
    no_system_prompt: true

scienceqa:
    _target_: llava.data.LLaVADataset
    data_path: /home/yunhaof/workspace/datasets/evaluation/scienceqa/scienceqa_train_12k.json
    media_dir: /home/yunhaof/workspace/datasets/evaluation/scienceqa/images

sharegpt4v_gpt4_100k:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets/ShareGPT4V/jason-filter-sharegpt4v_instruct_gpt4-vision_cap100k.json
    media_dir: /home/jasonlu/vlm_datasets/ShareGPT4V/data

sharegpt4v_sft:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets/ShareGPT4V/jason-filter-sharegpt4v_mix665k_cap23k_coco-ap9k_lcs3k_sam9k_div2k.json
    media_dir: /home/jasonlu/vlm_datasets/ShareGPT4V/data

sharegpt_video:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/video_datasets_v2/sharegpt_video/video_caption_pretrain.json
    media_dir: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/video_datasets_v2/sharegpt_video/videos

sherlock:
    _target_: llava.data.LLaVADataset
    data_path: /home/yunhaof/workspace/datasets/sherlock/processed/sherlock_317k.json
    media_dir: /home/yunhaof/workspace/datasets/sherlock/images

shot2story_shotonly:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/shot2story/train-shortclip-processed-bin.json
    media_dir: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/shot2story/Shot2Story/data/videos_extracted

synthdog_en:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/workspace/InternVL/internvl_chat/playground/synthdog_en.jsonl
    media_dir: /home/jasonlu/workspace/InternVL/internvl_chat/playground/data/synthdog-en

text_flan_1m:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/text_flan_1m/data.json
    no_system_prompt: true

vatex:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/video_datasets/jason_filtered_vatex.json
    media_dir: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/video_datasets_v2/vatex/videos_clipped

video_chatgpt:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/video_chatgpt/data.json
    media_dir: /home/jasonlu/video_datasets/Video_ChatGPT/activitynet_videos

vqa_activitynet-qa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_activitynet-qa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_activitynet-qa_train/images
    no_system_prompt: true

vqa_docvqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_docvqa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_docvqa_train/images
    no_system_prompt: true

vqa_gqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_gqa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_gqa_train/images
    no_system_prompt: true

vqa_ivqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_ivqa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_ivqa_train/images
    no_system_prompt: true

vqa_msrvtt-qa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_msrvtt-qa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_msrvtt-qa_train/images
    no_system_prompt: true

vqa_msvd-qa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_msvd-qa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_msvd-qa_train/images
    no_system_prompt: true

vqa_ocr-vqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_ocr-vqa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_ocr-vqa_train/images
    no_system_prompt: true

vqa_st-vqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_st-vqa_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_st-vqa_train/images
    no_system_prompt: true

vqa_viquae_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_viquae_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_viquae_train/images
    no_system_prompt: true

vqa_vqa-v2_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/zhijianl/workspace/datasets/vflan/vqa_vqa-v2_train/data.json
    media_dir: /home/zhijianl/workspace/datasets/vflan/vqa_vqa-v2_train/images
    no_system_prompt: true

wit_subset:
    _target_: llava.data.LLaVADataset
    data_path: /home/yunhaof/workspace/datasets/WIT/wit_1_8m/wit_processed_538k.json
    media_dir: /home/yunhaof/workspace/datasets/WIT/wit_1_8m/images

youcook2:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/video_datasets/jason_filtered_youcook2.json
    media_dir: /lustre/fsw/portfolios/nvr/projects/nvr_elm_llm/dataset/video_datasets_v2/youcook2/video_data_clipped

docmatix_750k:
    _target_: llava.data.LLaVADataset
    data_path: /home/baifengs/baifengs/data/Docmatix/conversations_750k.json
    media_dir: /home/baifengs/baifengs/data/Docmatix

docmatix_2:
    _target_: llava.data.LLaVADataset
    data_path: /home/baifengs/baifengs/data/Docmatix/conversations_750000-1000000.json
    media_dir: /home/baifengs/baifengs/data/Docmatix

docmatix_3:
    _target_: llava.data.LLaVADataset
    data_path: /home/baifengs/baifengs/data/Docmatix/conversations_1000000-1250000.json
    media_dir: /home/baifengs/baifengs/data/Docmatix

doc_reason:
    _target_: llava.data.LLaVADataset
    data_path: /home/haotiant/workspace/dataset/vila_data/DocReason25K/docreason25k_processed.jsonl
    media_dir: /home/haotiant/workspace/dataset/vila_data/DocReason25K

kvqa:
    _target_: llava.data.LLaVADataset
    data_path: /home/haotiant/workspace/dataset/vila_data/kvqa/raw/kvqa_processed.json
    media_dir: /home/haotiant/workspace/dataset/vila_data/kvqa/raw

metamathqa:
    _target_: llava.data.LLaVADataset
    data_path: /home/haotiant/workspace/dataset/vila_data/MetaMathQA/MetaMathQA-395K_processed.json

mminstruct:
    _target_: llava.data.LLaVADataset
    data_path: /home/haotiant/dataset/vila_data/MMInstruct/jsons_all/qa_en.jsonl
    media_dir: /home/haotiant/dataset/vila_data/MMInstruct/images

unichart:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets2/unichart-qa-data/unichart-qa_processed.jsonl
    media_dir: /home/jasonlu/vlm_datasets2/unichart-qa-data/images

mtwi:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets3/mtwi_train/mtwi_processed.jsonl
    media_dir: /home/jasonlu/vlm_datasets3/mtwi_train/image_train

art:
    _target_: llava.data.LLaVADataset
    data_path: /home/haotiant/dataset/vila_data/art_shangy/art500k_processed.jsonl
    media_dir: /home/haotiant/dataset/vila_data/art_shangy

art1:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets3/ART/ART_processed1.jsonl
    media_dir: /home/jasonlu/vlm_datasets3/ART/train_images

art2:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets3/ART/ART_processed2.jsonl
    media_dir: /home/jasonlu/vlm_datasets3/ART/train_task2_images

lsvt:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets3/LSVT/LSVT_processed.jsonl
    media_dir: /home/jasonlu/vlm_datasets3/LSVT/train_full_images

unichart-pretrain:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets3/unichart-pretrain-data/unichart-pretrain_processed.jsonl
    media_dir: /home/jasonlu/vlm_datasets3/UniChart-pretrain-images/content/images

rects:
    _target_: llava.data.LLaVADataset
    data_path: /home/jasonlu/vlm_datasets3/ReCTS/ReCTS_processed.jsonl
    media_dir: /home/jasonlu/vlm_datasets3/ReCTS/img

koniq:
    _target_: llava.data.LLaVADataset
    data_path: /home/shangy/label/koniq10k/koniq10k.jsonl
    media_dir: /home/shangy/label/koniq10k/koniq10k

casia:
    _target_: llava.data.LLaVADataset
    data_path: /home/shangy/label/CASIA/CASIA2.0_revised/Au.jsonl
    media_dir: /home/shangy/label/CASIA/CASIA2.0_revised/Au

pdfa-1m:
    _target_: llava.data.LLaVADataset
    data_path: /home/baifengs/baifengs/data/pdfa/vanilla_qa/pdfa_1m.json
    media_dir: /home/baifengs/baifengs/data/pdfa/vanilla_qa
