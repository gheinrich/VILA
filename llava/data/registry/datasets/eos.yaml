---
shot2story_shotonly:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/shot2story/train-shortclip-processed-bin.json
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/shot2story/Shot2Story/data/videos_extracted

scienceqa:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/evaluation/scienceqa/scienceqa_train_12k.json
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/evaluation/scienceqa/images

sharegpt4v_sft:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/ShareGPT4V/jason-filter-sharegpt4v_mix665k_cap23k_coco-ap9k_lcs3k_sam9k_div2k.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/ShareGPT4V/data

########################### vflan ###########################
captioning_image-paragraph-captioning_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/captioning_image-paragraph-captioning_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/captioning_image-paragraph-captioning_train/images
    no_system_prompt: true

captioning_msrvtt_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/captioning_msrvtt_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/captioning_msrvtt_train/images
    no_system_prompt: true

captioning_textcap_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/captioning_textcap_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/captioning_textcap_train/images
    no_system_prompt: true

chartqa_train_18k:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/InternVL/internvl_chat/playground/chartqa_train_18k.jsonl
    media_dir: /home/ligengz/nvr_elm_llm/dataset/InternVL/internvl_chat/playground/data/chartqa

docvqa_train_10k:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/InternVL/internvl_chat/playground/docvqa_train_10k.jsonl
    media_dir: /home/ligengz/nvr_elm_llm/dataset/InternVL/internvl_chat/playground/data/docvqa

dvqa_train_200k:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/InternVL/internvl_chat/playground/dvqa_train_200k.jsonl
    media_dir: /home/ligengz/nvr_elm_llm/dataset/InternVL/internvl_chat/playground/data/dvqa

generation_visual-dialog_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/generation_visual-dialog_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/generation_visual-dialog_train/images
    no_system_prompt: true

llava-video/academic-cap:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/academic-cap.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/academic-mc:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/academic-mc.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/academic-oe:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/academic-oe.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/activitynetqa-oe:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/activitynetqa-oe.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/nextqa-mc:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/nextqa-mc.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/nextqa-oe:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/nextqa-oe.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/perceptiontest-mc:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/perceptiontest-mc.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/sharegptvideo-cap:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/sharegptvideo-cap.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/sharegpt-video/videos

llava-video/sharegptvideo-oe:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/sharegptvideo-oe.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/sharegpt-video/videos

llava-video/youtube-cap:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/youtube-cap.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/youtube-mc:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/youtube-mc.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

llava-video/youtube-oe:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/datasets/llava-video/youtube-oe.json
    media_dir: /lustre/fsw/nvr_elm_llm/datasets/llava-video/videos

reasoning_clevr_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/reasoning_clevr_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/reasoning_clevr_train/images
    no_system_prompt: true

reasoning_nlvr_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/reasoning_nlvr_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/reasoning_nlvr_train/images
    no_system_prompt: true

reasoning_visual-mrc_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/reasoning_visual-mrc_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/reasoning_visual-mrc_train/images
    no_system_prompt: true

vqa_activitynet-qa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_activitynet-qa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_activitynet-qa_train/images
    no_system_prompt: true

vqa_docvqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_docvqa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_docvqa_train/images
    no_system_prompt: true

vqa_gqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_gqa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_gqa_train/images
    no_system_prompt: true

vqa_ivqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_ivqa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_ivqa_train/images
    no_system_prompt: true

vqa_msrvtt-qa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_msrvtt-qa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_msrvtt-qa_train/images
    no_system_prompt: true

vqa_msvd-qa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_msvd-qa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_msvd-qa_train/images
    no_system_prompt: true

vqa_ocr-vqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_ocr-vqa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_ocr-vqa_train/images
    no_system_prompt: true

vqa_st-vqa_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_st-vqa_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_st-vqa_train/images
    no_system_prompt: true

vqa_viquae_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_viquae_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_viquae_train/images
    no_system_prompt: true

vqa_vqa-v2_train:
    _target_: llava.data.LLaVADataset
    data_path: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_vqa-v2_train/data.json
    media_dir: /home/ligengz/nvr_elm_llm/dataset/vflan/vqa_vqa-v2_train/images
    no_system_prompt: true

llava_1_5_mm_align:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/LLaVA-CC3M-Pretrain-595K/chat.json
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/LLaVA-CC3M-Pretrain-595K/images

allava_caption_vflan:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/ALLaVA-4V/ALLaVA-Caption-VFLAN-4V.json
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/ALLaVA-4V/

docmatix_2:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/Docmatix/conversations_750000-1000000.json
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/Docmatix

docmatix_3:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/Docmatix/conversations_1000000-1250000.json
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/Docmatix

pdfa-1m:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/pdfa/vanilla_qa/pdfa_1m.json
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-pretrain/pdfa/vanilla_qa

unichart-pretrain-1m:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/unichart-pretrain-data/unichart-pretrain_processed_1m.jsonl
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/UniChart-pretrain-images/content/images

mtwi:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/mtwi_train/mtwi_processed.jsonl
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/mtwi_train/image_train

art1:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/ART/ART_processed1.jsonl
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/ART/train_images

art2:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/ART/ART_processed2.jsonl
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/ART/train_task2_images

lsvt:
    _target_: llava.data.LLaVADataset
    data_path: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/LSVT/LSVT_processed.jsonl
    media_dir: /lustre/fsw/nvr_elm_llm/dataset/vila-sft/LSVT/train_full_images
